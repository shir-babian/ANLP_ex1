{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S6EIOG0xGfjg",
        "outputId": "966ef4fd-d233-48ae-b742-74e12209a88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.10)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.27.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Starting the process...\n",
            "requirements.txt file created successfully!\n",
            "Loading MRPC dataset from nyu-mll/glue...\n",
            "Training: 3668 examples\n",
            "Validation: 408 examples\n",
            "Test: 1725 examples\n",
            "\n",
            "=== Experiment 1: 1 epoch, learning rate 0.01, batch size 16 ===\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250511_121345-it151b0r</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/it151b0r' target=\"_blank\">epochs_1_lr_0.01_bs_16</a></strong> to <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/it151b0r' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/it151b0r</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-4-c26e5efa7a98>:733: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer1 = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [230/230 01:03, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.739300</td>\n",
              "      <td>0.629914</td>\n",
              "      <td>0.683824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='134' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/26 00:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added results to res.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>██▁</td></tr><tr><td>eval/loss</td><td>▁▁█</td></tr><tr><td>eval/runtime</td><td>▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▁▂█</td></tr><tr><td>eval/steps_per_second</td><td>▁▃█</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇██████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▄▇▂▅▄▅▄▁▂▄▆█▄▄▁▂▃▂▄▁▄▁▄</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▂▂▁▁▁▃▃▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.66493</td></tr><tr><td>eval/loss</td><td>0.64011</td></tr><tr><td>eval/runtime</td><td>6.9929</td></tr><tr><td>eval/samples_per_second</td><td>246.68</td></tr><tr><td>eval/steps_per_second</td><td>15.444</td></tr><tr><td>total_flos</td><td>142935080824320.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>230</td></tr><tr><td>train/grad_norm</td><td>12.07291</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>0.7393</td></tr><tr><td>train_loss</td><td>1.16333</td></tr><tr><td>train_runtime</td><td>64.1464</td></tr><tr><td>train_samples_per_second</td><td>57.182</td></tr><tr><td>train_steps_per_second</td><td>3.586</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">epochs_1_lr_0.01_bs_16</strong> at: <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/it151b0r' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/it151b0r</a><br> View project at: <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250511_121345-it151b0r/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Experiment 2: 3 epochs, learning rate 4e-5, batch size 16 ===\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250511_121505-6fn3hatn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/6fn3hatn' target=\"_blank\">epochs_3_lr_4e-5_bs_16</a></strong> to <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/6fn3hatn' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/6fn3hatn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-4-c26e5efa7a98>:793: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer2 = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [690/690 03:22, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.418900</td>\n",
              "      <td>0.366390</td>\n",
              "      <td>0.862745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.190500</td>\n",
              "      <td>0.415889</td>\n",
              "      <td>0.857843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.178300</td>\n",
              "      <td>0.646590</td>\n",
              "      <td>0.852941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='134' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/26 00:09]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added results to res.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▇▆█▁</td></tr><tr><td>eval/loss</td><td>▁▂█▁▂</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▄▁▂▆█</td></tr><tr><td>eval/steps_per_second</td><td>▅▁▃█▆</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▂▁▁▂▁▂▁▂▂▂▁▂▂▂▂▂▂▂▂▂▃▂▂▂▂▃▃▃▂▂▁▂▁▄▂▁▁▃█</td></tr><tr><td>train/learning_rate</td><td>████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>███▇▇▆▆▇▆▇▆▆▅▄▅▄▄▄▄▃▄▃▂▅▄▃▂▂▂▃▁▂▂▂▂▂▂▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.82725</td></tr><tr><td>eval/loss</td><td>0.40791</td></tr><tr><td>eval/runtime</td><td>7.4863</td></tr><tr><td>eval/samples_per_second</td><td>230.421</td></tr><tr><td>eval/steps_per_second</td><td>14.426</td></tr><tr><td>total_flos</td><td>428577075854640.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>690</td></tr><tr><td>train/grad_norm</td><td>52.06588</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1783</td></tr><tr><td>train_loss</td><td>0.31979</td></tr><tr><td>train_runtime</td><td>202.3886</td></tr><tr><td>train_samples_per_second</td><td>54.371</td></tr><tr><td>train_steps_per_second</td><td>3.409</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">epochs_3_lr_4e-5_bs_16</strong> at: <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/6fn3hatn' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/6fn3hatn</a><br> View project at: <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250511_121505-6fn3hatn/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Experiment 3: 5 epochs, learning rate 5e-5, batch size 16 ===\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250511_121842-wbbr7eyy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/wbbr7eyy' target=\"_blank\">epochs_5_lr_5e-5_bs_16</a></strong> to <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/wbbr7eyy' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/wbbr7eyy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-4-c26e5efa7a98>:853: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer3 = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1150' max='1150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1150/1150 05:36, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.432800</td>\n",
              "      <td>0.377360</td>\n",
              "      <td>0.843137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.210300</td>\n",
              "      <td>0.360460</td>\n",
              "      <td>0.870098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.162300</td>\n",
              "      <td>0.463471</td>\n",
              "      <td>0.865196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.132600</td>\n",
              "      <td>0.620267</td>\n",
              "      <td>0.870098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.143200</td>\n",
              "      <td>0.651791</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='134' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/26 00:09]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added results to res.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▂▇▆▇██▁</td></tr><tr><td>eval/loss</td><td>▁▁▃▅▆▆█</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▄▂▃▂▁▄█</td></tr><tr><td>eval/steps_per_second</td><td>▆▃▅▃▁▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▁▂▂▂▁▁▂▁▁▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁█▁▂▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>██▇▇▆▆▄▄▅▅▅▄▄▃▄▅▃▃▂▂▁▃▃▂▂▂▁▂▂▂▂▁▂▃▂▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.83652</td></tr><tr><td>eval/loss</td><td>0.80831</td></tr><tr><td>eval/runtime</td><td>7.4997</td></tr><tr><td>eval/samples_per_second</td><td>230.01</td></tr><tr><td>eval/steps_per_second</td><td>14.401</td></tr><tr><td>total_flos</td><td>714950848507680.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>1150</td></tr><tr><td>train/grad_norm</td><td>0.06935</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1432</td></tr><tr><td>train_loss</td><td>0.23743</td></tr><tr><td>train_runtime</td><td>336.9052</td></tr><tr><td>train_samples_per_second</td><td>54.437</td></tr><tr><td>train_steps_per_second</td><td>3.413</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">epochs_5_lr_5e-5_bs_16</strong> at: <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/wbbr7eyy' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1/runs/wbbr7eyy</a><br> View project at: <a href='https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1' target=\"_blank\">https://wandb.ai/shir-babian-hebrew-university-of-jerusalem/anlp_ex1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250511_121842-wbbr7eyy/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss.png graph created successfully\n",
            "\n",
            "The best model is: model_ep5_lr00005_bs16 with validation accuracy of 0.8750 and test accuracy of 0.8365\n",
            "\n",
            "=== Finding examples where models completely disagree (one predicts 0, one predicts 1) ===\n",
            "\n",
            "Worst model: 1 epoch, lr=0.01\n",
            "Best model: model_ep5_lr00005_bs16 with accuracy 0.8750\n",
            "Worst model: model_ep1_lr001_bs16 with accuracy 0.6838\n",
            "Analysis complete. Found 114 examples where models completely disagree.\n",
            "Results saved to complete_disagreement_examples.txt\n",
            "\n",
            "Examples where best model correctly predicted and worst model was wrong:\n",
            "\n",
            "Example 1:\n",
            "Sentence 1: Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war .\n",
            "Sentence 2: His wife said he was \" 100 percent behind George Bush \" and looked forward to using his years of training in the war .\n",
            "True label: 0 (Not paraphrase)\n",
            "Best model: Correct (0) with confidence 0.9953\n",
            "Worst model: Wrong (1) with confidence 0.6317\n",
            "\n",
            "Example 2:\n",
            "Sentence 1: The dollar was at 116.92 yen against the yen , flat on the session , and at 1.2891 against the Swiss franc , also flat .\n",
            "Sentence 2: The dollar was at 116.78 yen JPY = , virtually flat on the session , and at 1.2871 against the Swiss franc CHF = , down 0.1 percent .\n",
            "True label: 0 (Not paraphrase)\n",
            "Best model: Correct (0) with confidence 0.9924\n",
            "Worst model: Wrong (1) with confidence 0.6317\n",
            "\n",
            "Example 3:\n",
            "Sentence 1: No dates have been set for the civil or the criminal trial .\n",
            "Sentence 2: No dates have been set for the criminal or civil cases , but Shanley has pleaded not guilty .\n",
            "True label: 0 (Not paraphrase)\n",
            "Best model: Correct (0) with confidence 0.9943\n",
            "Worst model: Wrong (1) with confidence 0.6317\n",
            "\n",
            "Example 4:\n",
            "Sentence 1: \" Sanitation is poor ... there could be typhoid and cholera , \" he said .\n",
            "Sentence 2: \" Sanitation is poor , drinking water is generally left behind . . . there could be typhoid and cholera . \"\n",
            "True label: 0 (Not paraphrase)\n",
            "Best model: Correct (0) with confidence 0.9949\n",
            "Worst model: Wrong (1) with confidence 0.6317\n",
            "\n",
            "Example 5:\n",
            "Sentence 1: The broader Standard & Poor 's 500 Index .SPX gave up 11.91 points , or 1.19 percent , at 986.60 .\n",
            "Sentence 2: The technology-laced Nasdaq Composite Index was down 25.36 points , or 1.53 percent , at 1,628.26 .\n",
            "True label: 0 (Not paraphrase)\n",
            "Best model: Correct (0) with confidence 0.9920\n",
            "Worst model: Wrong (1) with confidence 0.6317\n",
            "\n",
            "=== Generating predictions with the best model ===\n",
            "\n",
            "Creating predictions without padding...\n",
            "Generated 1725 predictions\n",
            "Predictions saved to predictions.txt\n",
            "ex1.py file created successfully!\n",
            "\n",
            "All required files have been successfully created!\n",
            "- ex1.py: Complete code file with support for all required arguments\n",
            "- res.txt: Results file with validation and test accuracy for all configurations\n",
            "- predictions.txt: Predictions file from the best model on the test set\n",
            "- requirements.txt: File with all required packages\n",
            "- train_loss.png: Training loss graph\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Installing required packages\n",
        "!pip install transformers datasets torch wandb scikit-learn matplotlib\n",
        "\n",
        "# Importing all required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import wandb\n",
        "\n",
        "# Setting constants - you can change them here\n",
        "MAX_TRAIN_SAMPLES = -1  # All training examples\n",
        "MAX_EVAL_SAMPLES = -1   # All validation examples\n",
        "MAX_TEST_SAMPLES = -1   # All test examples\n",
        "\n",
        "# Setting random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Creating requirements.txt file\n",
        "def create_requirements_file():\n",
        "    with open(\"requirements.txt\", \"w\") as f:\n",
        "        f.write(\"transformers>=4.28.0\\n\")\n",
        "        f.write(\"datasets>=2.12.0\\n\")\n",
        "        f.write(\"torch>=2.0.0\\n\")\n",
        "        f.write(\"wandb>=0.15.0\\n\")\n",
        "        f.write(\"scikit-learn>=1.2.0\\n\")\n",
        "        f.write(\"numpy>=1.24.0\\n\")\n",
        "        f.write(\"matplotlib>=3.5.0\\n\")\n",
        "    print(\"requirements.txt file created successfully!\")\n",
        "\n",
        "# Loading MRPC dataset\n",
        "def load_mrpc_dataset(max_train_samples=-1, max_eval_samples=-1, max_test_samples=-1):\n",
        "    print(\"Loading MRPC dataset from nyu-mll/glue...\")\n",
        "    dataset = load_dataset(\"nyu-mll/glue\", \"mrpc\")\n",
        "\n",
        "    # Limiting the number of examples if required\n",
        "    if max_train_samples > 0 and max_train_samples < len(dataset[\"train\"]):\n",
        "        dataset[\"train\"] = dataset[\"train\"].select(range(max_train_samples))\n",
        "\n",
        "    if max_eval_samples > 0 and max_eval_samples < len(dataset[\"validation\"]):\n",
        "        dataset[\"validation\"] = dataset[\"validation\"].select(range(max_eval_samples))\n",
        "\n",
        "    if max_test_samples > 0 and max_test_samples < len(dataset[\"test\"]):\n",
        "        dataset[\"test\"] = dataset[\"test\"].select(range(max_test_samples))\n",
        "\n",
        "    print(f\"Training: {len(dataset['train'])} examples\")\n",
        "    print(f\"Validation: {len(dataset['validation'])} examples\")\n",
        "    print(f\"Test: {len(dataset['test'])} examples\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Function to preprocess the dataset\n",
        "def preprocess_function(examples, tokenizer):\n",
        "    return tokenizer(\n",
        "        examples[\"sentence1\"],\n",
        "        examples[\"sentence2\"],\n",
        "        truncation=True,\n",
        "        padding=False,  # Dynamic padding will be done by the data collator\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "# Function to compute metrics for evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
        "\n",
        "# Function to log results to res.txt\n",
        "def log_results(num_epochs, lr, batch_size, eval_acc, test_acc):\n",
        "    with open(\"res.txt\", \"a\") as f:\n",
        "        f.write(f\"epoch_num: {num_epochs}, lr: {lr}, batch_size: {batch_size}, eval_acc: {eval_acc:.4f}, test_acc: {test_acc:.4f}\\n\")\n",
        "    print(f\"Added results to res.txt\")\n",
        "\n",
        "# Generating predictions\n",
        "def generate_predictions(model, tokenizer, test_dataset, original_test_data):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(\"Creating predictions without padding...\")\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "    # Processing each example separately without padding\n",
        "    for i in range(len(test_dataset)):\n",
        "        # Getting the tokenized input\n",
        "        item = test_dataset[i]\n",
        "\n",
        "        # Creating tensors\n",
        "        input_ids = torch.tensor(item[\"input_ids\"], dtype=torch.long).unsqueeze(0)\n",
        "        attention_mask = torch.tensor(item[\"attention_mask\"], dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "        # Moving to device\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "\n",
        "        # Making prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        prediction = torch.argmax(logits, dim=-1).item()\n",
        "        all_predictions.append(prediction)\n",
        "\n",
        "    print(f\"Generated {len(all_predictions)} predictions\")\n",
        "\n",
        "    # Writing predictions to file\n",
        "    with open(\"predictions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, pred in enumerate(all_predictions):\n",
        "            sentence1 = original_test_data[i][\"sentence1\"]\n",
        "            sentence2 = original_test_data[i][\"sentence2\"]\n",
        "            f.write(f\"{sentence1}###{sentence2}###{pred}\\n\")\n",
        "\n",
        "    print(\"Predictions saved to predictions.txt\")\n",
        "    return all_predictions\n",
        "\n",
        "# Analyzing differences between models\n",
        "def analyze_model_differences(best_model, worst_model, tokenizer, validation_dataset, original_validation_data):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    best_model.to(device)\n",
        "    worst_model.to(device)\n",
        "\n",
        "    best_model.eval()\n",
        "    worst_model.eval()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i in range(len(validation_dataset)):\n",
        "        # Get example and original text\n",
        "        item = validation_dataset[i]\n",
        "        original_example = original_validation_data[i]\n",
        "\n",
        "        # Create tensors\n",
        "        input_ids = torch.tensor(item[\"input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        attention_mask = torch.tensor(item[\"attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        true_label = item[\"labels\"]\n",
        "\n",
        "        # Get predictions from both models\n",
        "        with torch.no_grad():\n",
        "            best_outputs = best_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            worst_outputs = worst_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        best_pred = torch.argmax(best_outputs.logits, dim=-1).item()\n",
        "        worst_pred = torch.argmax(worst_outputs.logits, dim=-1).item()\n",
        "\n",
        "        # Calculate confidence scores\n",
        "        best_probs = torch.nn.functional.softmax(best_outputs.logits, dim=-1)\n",
        "        worst_probs = torch.nn.functional.softmax(worst_outputs.logits, dim=-1)\n",
        "\n",
        "        best_confidence = best_probs[0][best_pred].item()\n",
        "        worst_confidence = worst_probs[0][worst_pred].item()\n",
        "\n",
        "        # Store only examples where best model is correct and worst model is wrong\n",
        "        if best_pred == true_label and worst_pred != true_label:\n",
        "            results.append({\n",
        "                \"sentence1\": original_example[\"sentence1\"],\n",
        "                \"sentence2\": original_example[\"sentence2\"],\n",
        "                \"true_label\": true_label,\n",
        "                \"best_confidence\": best_confidence,\n",
        "                \"worst_confidence\": worst_confidence\n",
        "            })\n",
        "\n",
        "    # Save results to a file\n",
        "    with open(\"model_comparison.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"Found {len(results)} examples where best model succeeded but worst model failed\\n\\n\")\n",
        "\n",
        "        for i, example in enumerate(results):\n",
        "            f.write(f\"Example {i+1}:\\n\")\n",
        "            f.write(f\"Sentence 1: {example['sentence1']}\\n\")\n",
        "            f.write(f\"Sentence 2: {example['sentence2']}\\n\")\n",
        "            f.write(f\"True label: {example['true_label']} \" +\n",
        "                   f\"({'Paraphrase' if example['true_label'] == 1 else 'Not paraphrase'})\\n\")\n",
        "            f.write(f\"Best model confidence: {example['best_confidence']:.4f}\\n\")\n",
        "            f.write(f\"Worst model confidence: {example['worst_confidence']:.4f}\\n\\n\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_model_differences_complete_disagreement(best_model, worst_model, tokenizer, validation_dataset, original_validation_data):\n",
        "    \"\"\"\n",
        "    Find examples where the best model is correct and the worst model is wrong (with completely different predictions)\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    best_model.to(device)\n",
        "    worst_model.to(device)\n",
        "\n",
        "    best_model.eval()\n",
        "    worst_model.eval()\n",
        "\n",
        "    disagreement_examples = []  # Store examples where models completely disagree\n",
        "\n",
        "    for i in range(len(validation_dataset)):\n",
        "        # Get example and original text\n",
        "        item = validation_dataset[i]\n",
        "        original_example = original_validation_data[i]\n",
        "\n",
        "        # Create tensors\n",
        "        input_ids = torch.tensor(item[\"input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        attention_mask = torch.tensor(item[\"attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        true_label = item[\"labels\"]\n",
        "\n",
        "        # Get predictions from both models\n",
        "        with torch.no_grad():\n",
        "            best_outputs = best_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            worst_outputs = worst_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        best_pred = torch.argmax(best_outputs.logits, dim=-1).item()\n",
        "        worst_pred = torch.argmax(worst_outputs.logits, dim=-1).item()\n",
        "\n",
        "        # Calculate confidence scores\n",
        "        best_probs = torch.nn.functional.softmax(best_outputs.logits, dim=-1)\n",
        "        worst_probs = torch.nn.functional.softmax(worst_outputs.logits, dim=-1)\n",
        "\n",
        "        best_confidence = best_probs[0][best_pred].item()\n",
        "        worst_confidence = worst_probs[0][worst_pred].item()\n",
        "\n",
        "        # Store only examples where best model is correct, worst model is wrong, and they completely disagree\n",
        "        if best_pred == true_label and worst_pred != true_label and best_pred != worst_pred:\n",
        "            disagreement_examples.append({\n",
        "                \"id\": i,\n",
        "                \"sentence1\": original_example[\"sentence1\"],\n",
        "                \"sentence2\": original_example[\"sentence2\"],\n",
        "                \"true_label\": true_label,\n",
        "                \"best_pred\": best_pred,\n",
        "                \"worst_pred\": worst_pred,\n",
        "                \"best_confidence\": best_confidence,\n",
        "                \"worst_confidence\": worst_confidence,\n",
        "                \"sentence1_length\": len(original_example[\"sentence1\"].split()),\n",
        "                \"sentence2_length\": len(original_example[\"sentence2\"].split())\n",
        "            })\n",
        "\n",
        "    # Save results to a file\n",
        "    with open(\"complete_disagreement_examples.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"Found {len(disagreement_examples)} examples where best model is correct and worst model is wrong\\n\\n\")\n",
        "\n",
        "        for i, example in enumerate(disagreement_examples):\n",
        "            f.write(f\"Example {i+1}:\\n\")\n",
        "            f.write(f\"Sentence 1: {example['sentence1']}\\n\")\n",
        "            f.write(f\"Sentence 2: {example['sentence2']}\\n\")\n",
        "            f.write(f\"Sentence 1 length: {example['sentence1_length']} words\\n\")\n",
        "            f.write(f\"Sentence 2 length: {example['sentence2_length']} words\\n\")\n",
        "            f.write(f\"True label: {example['true_label']} ({'Paraphrase' if example['true_label'] == 1 else 'Not paraphrase'})\\n\")\n",
        "            f.write(f\"Best model prediction: {example['best_pred']} ({'Paraphrase' if example['best_pred'] == 1 else 'Not paraphrase'})\\n\")\n",
        "            f.write(f\"Worst model prediction: {example['worst_pred']} ({'Paraphrase' if example['worst_pred'] == 1 else 'Not paraphrase'})\\n\")\n",
        "            f.write(f\"Best model confidence: {example['best_confidence']:.4f}\\n\")\n",
        "            f.write(f\"Worst model confidence: {example['worst_confidence']:.4f}\\n\\n\")\n",
        "\n",
        "    return disagreement_examples\n",
        "\n",
        "# Edge case analysis function\n",
        "def find_edge_cases(best_model, worst_model, tokenizer, validation_dataset, original_validation_data):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    best_model.to(device)\n",
        "    worst_model.to(device)\n",
        "\n",
        "    best_model.eval()\n",
        "    worst_model.eval()\n",
        "\n",
        "    edge_cases = []\n",
        "\n",
        "    for i in range(len(validation_dataset)):\n",
        "        item = validation_dataset[i]\n",
        "        original_example = original_validation_data[i]\n",
        "\n",
        "        input_ids = torch.tensor(item[\"input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        attention_mask = torch.tensor(item[\"attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)\n",
        "        true_label = item[\"labels\"]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            best_outputs = best_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            worst_outputs = worst_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Computing probabilities for each label\n",
        "        best_probs = torch.nn.functional.softmax(best_outputs.logits, dim=-1)\n",
        "        worst_probs = torch.nn.functional.softmax(worst_outputs.logits, dim=-1)\n",
        "\n",
        "        # Check if best model is confident about correct label while worst model is uncertain\n",
        "        best_true_conf = best_probs[0][true_label].item()\n",
        "        worst_true_conf = worst_probs[0][true_label].item()\n",
        "        worst_opposite_conf = worst_probs[0][1 - true_label].item()\n",
        "\n",
        "        # Finding cases where:\n",
        "        # 1. The best model is very confident about the correct answer\n",
        "        # 2. The worst model is almost 50/50 (close decision boundary)\n",
        "        if best_true_conf > 0.75 and worst_true_conf < 0.6 and worst_true_conf > 0.4:\n",
        "            edge_cases.append({\n",
        "                \"sentence1\": original_example[\"sentence1\"],\n",
        "                \"sentence2\": original_example[\"sentence2\"],\n",
        "                \"true_label\": true_label,\n",
        "                \"best_true_conf\": best_true_conf,\n",
        "                \"worst_true_conf\": worst_true_conf,\n",
        "                \"worst_opposite_conf\": worst_opposite_conf\n",
        "            })\n",
        "\n",
        "    return edge_cases\n",
        "\n",
        "# Creating loss plot\n",
        "def create_loss_plot(all_losses, all_configs):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.title('Training Loss vs Steps')\n",
        "\n",
        "    for i, (losses, config) in enumerate(zip(all_losses, all_configs)):\n",
        "        # For a smoother graph, selecting a sample of points\n",
        "        if len(losses) > 100:\n",
        "            step = max(1, len(losses) // 100)\n",
        "            indices = np.arange(0, len(losses), step)\n",
        "            selected_losses = [losses[j] for j in indices]\n",
        "        else:\n",
        "            selected_losses = losses\n",
        "\n",
        "        # Plotting the graph with appropriate label format\n",
        "        plt.plot(\n",
        "            selected_losses,\n",
        "            label=f\"epoch_num_{config['num_epochs']}_lr_{config['lr']}_batch_size_{config['batch_size']}\"\n",
        "        )\n",
        "\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('train_loss.png')\n",
        "    print(\"train_loss.png graph created successfully\")\n",
        "\n",
        "# Creating ex1.py file for submission\n",
        "def create_ex1_file():\n",
        "    ex1_code = '''#!/usr/bin/env python\n",
        "\"\"\"\n",
        "Fine-tuning BERT for paraphrase detection on the MRPC dataset.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.StreamHandler(sys.stdout)]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"Parse command line arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Fine-tune BERT on MRPC dataset\")\n",
        "    parser.add_argument(\"--max_train_samples\", type=int, default=-1,\n",
        "                        help=\"Max number of training samples to use (-1 for all)\")\n",
        "    parser.add_argument(\"--max_eval_samples\", type=int, default=-1,\n",
        "                        help=\"Max number of evaluation samples to use (-1 for all)\")\n",
        "    parser.add_argument(\"--max_predict_samples\", type=int, default=-1,\n",
        "                        help=\"Max number of prediction samples to use (-1 for all)\")\n",
        "    parser.add_argument(\"--num_train_epochs\", type=int, default=3,\n",
        "                        help=\"Number of training epochs\")\n",
        "    parser.add_argument(\"--lr\", type=float, default=5e-5,\n",
        "                        help=\"Learning rate\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=16,\n",
        "                        help=\"Batch size for training and evaluation\")\n",
        "    parser.add_argument(\"--do_train\", action=\"store_true\",\n",
        "                        help=\"Whether to run training\")\n",
        "    parser.add_argument(\"--do_predict\", action=\"store_true\",\n",
        "                        help=\"Whether to run predictions on the test set\")\n",
        "    parser.add_argument(\"--model_path\", type=str, default=None,\n",
        "                        help=\"Path to model to use for predictions\")\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "def preprocess_function(examples, tokenizer):\n",
        "    \"\"\"Preprocess dataset with tokenizer.\"\"\"\n",
        "    return tokenizer(\n",
        "        examples[\"sentence1\"],\n",
        "        examples[\"sentence2\"],\n",
        "        truncation=True,\n",
        "        padding=False,  # Dynamic padding will be done by the data collator\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for evaluation.\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
        "\n",
        "def load_mrpc_dataset(max_train_samples=-1, max_eval_samples=-1, max_predict_samples=-1):\n",
        "    \"\"\"\n",
        "    Load the MRPC dataset from Hugging Face - specifically from nyu-mll/glue\n",
        "    \"\"\"\n",
        "    logger.info(\"Loading MRPC dataset from nyu-mll/glue...\")\n",
        "    dataset = load_dataset(\"nyu-mll/glue\", \"mrpc\")\n",
        "\n",
        "    # Apply sample limits if specified\n",
        "    if max_train_samples > 0 and max_train_samples < len(dataset[\"train\"]):\n",
        "        dataset[\"train\"] = dataset[\"train\"].select(range(max_train_samples))\n",
        "\n",
        "    if max_eval_samples > 0 and max_eval_samples < len(dataset[\"validation\"]):\n",
        "        dataset[\"validation\"] = dataset[\"validation\"].select(range(max_eval_samples))\n",
        "\n",
        "    if max_predict_samples > 0 and max_predict_samples < len(dataset[\"test\"]):\n",
        "        dataset[\"test\"] = dataset[\"test\"].select(range(max_predict_samples))\n",
        "\n",
        "    logger.info(f\"Train: {len(dataset['train'])} examples\")\n",
        "    logger.info(f\"Validation: {len(dataset['validation'])} examples\")\n",
        "    logger.info(f\"Test: {len(dataset['test'])} examples\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def generate_predictions(model, tokenizer, test_dataset, args):\n",
        "    \"\"\"\n",
        "    Generate predictions on the test set without padding.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Get original test examples for sentence reconstruction\n",
        "    original_test = load_dataset(\"nyu-mll/glue\", \"mrpc\", split=\"test\")\n",
        "    if args.max_predict_samples > 0:\n",
        "        original_test = original_test.select(range(min(args.max_predict_samples, len(original_test))))\n",
        "\n",
        "    # Process one sample at a time to avoid padding\n",
        "    logger.info(\"Creating test dataset loader for prediction without padding...\")\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "    # Process each example individually without padding\n",
        "    for i in range(len(test_dataset)):\n",
        "        # Get the tokenized input\n",
        "        item = test_dataset[i]\n",
        "\n",
        "        # Create tensors\n",
        "        input_ids = torch.tensor(item[\"input_ids\"], dtype=torch.long).unsqueeze(0)\n",
        "        attention_mask = torch.tensor(item[\"attention_mask\"], dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "        # Move to device\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "\n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        prediction = torch.argmax(logits, dim=-1).item()\n",
        "        all_predictions.append(prediction)\n",
        "\n",
        "    logger.info(f\"Generated {len(all_predictions)} predictions\")\n",
        "\n",
        "    # Write predictions to file\n",
        "    with open(\"predictions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, pred in enumerate(all_predictions):\n",
        "            sentence1 = original_test[i][\"sentence1\"]\n",
        "            sentence2 = original_test[i][\"sentence2\"]\n",
        "            f.write(f\"{sentence1}###{sentence2}###{pred}\\\\n\")\n",
        "\n",
        "    logger.info(\"Predictions saved to predictions.txt\")\n",
        "    return all_predictions\n",
        "\n",
        "def create_requirements_file():\n",
        "    \"\"\"\n",
        "    Create requirements.txt file.\n",
        "    \"\"\"\n",
        "    with open(\"requirements.txt\", \"w\") as f:\n",
        "        f.write(\"transformers>=4.28.0\\\\n\")\n",
        "        f.write(\"datasets>=2.12.0\\\\n\")\n",
        "        f.write(\"torch>=2.0.0\\\\n\")\n",
        "        f.write(\"wandb>=0.15.0\\\\n\")\n",
        "        f.write(\"scikit-learn>=1.2.0\\\\n\")\n",
        "        f.write(\"numpy>=1.24.0\\\\n\")\n",
        "        f.write(\"matplotlib>=3.5.0\\\\n\")\n",
        "    logger.info(\"Created requirements.txt\")\n",
        "\n",
        "def main():\n",
        "    # Parse arguments\n",
        "    args = parse_args()\n",
        "\n",
        "    # Set random seeds for reproducibility\n",
        "    set_seed(42)\n",
        "\n",
        "    # Create requirements.txt\n",
        "    create_requirements_file()\n",
        "\n",
        "    # Load dataset\n",
        "    dataset = load_mrpc_dataset(\n",
        "        max_train_samples=args.max_train_samples,\n",
        "        max_eval_samples=args.max_eval_samples,\n",
        "        max_predict_samples=args.max_predict_samples\n",
        "    )\n",
        "\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    # Tokenize dataset\n",
        "    tokenized_datasets = dataset.map(\n",
        "        lambda x: preprocess_function(x, tokenizer),\n",
        "        batched=True,\n",
        "        remove_columns=[\"idx\", \"sentence1\", \"sentence2\"]\n",
        "    )\n",
        "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "    if args.do_train:\n",
        "        # Load model\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            \"bert-base-uncased\",\n",
        "            num_labels=2\n",
        "        )\n",
        "\n",
        "        # Initialize wandb\n",
        "        run_name = f\"epochnum{args.num_train_epochs}lr{args.lr}_batchsize{args.batch_size}\"\n",
        "        try:\n",
        "            import wandb\n",
        "            wandb.init(project=\"mrpc-paraphrase-detection\", name=run_name)\n",
        "            logger.info(\"Successfully initialized Weights & Biases\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error initializing Weights & Biases: {e}\")\n",
        "            logger.info(\"Continuing without wandb tracking\")\n",
        "\n",
        "        # Create data collator\n",
        "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "        # Set up training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=f\"./results_ep{args.num_train_epochs}_lr{args.lr}_bs{args.batch_size}\",\n",
        "            eval_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            learning_rate=args.lr,\n",
        "            per_device_train_batch_size=args.batch_size,\n",
        "            per_device_eval_batch_size=args.batch_size,\n",
        "            num_train_epochs=args.num_train_epochs,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir=\"./logs\",\n",
        "            logging_steps=10,\n",
        "            report_to=\"wandb\",\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"accuracy\",\n",
        "            seed=42\n",
        "        )\n",
        "\n",
        "        # Initialize Trainer\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=tokenized_datasets[\"train\"],\n",
        "            eval_dataset=tokenized_datasets[\"validation\"],\n",
        "            compute_metrics=compute_metrics,\n",
        "            tokenizer=tokenizer,\n",
        "            data_collator=data_collator\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        trainer.train()\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        eval_results = trainer.evaluate()\n",
        "        logger.info(f\"Validation results: {eval_results}\")\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "        logger.info(f\"Test results: {test_results}\")\n",
        "\n",
        "        # Save model\n",
        "        model_save_path = f\"./modelepoch{args.num_train_epochs}lr{args.lr}_batchsize{args.batch_size}\"\n",
        "        trainer.save_model(model_save_path)\n",
        "        tokenizer.save_pretrained(model_save_path)\n",
        "        logger.info(f\"Saved model to {model_save_path}\")\n",
        "\n",
        "        # Save results to res.txt\n",
        "        with open(\"res.txt\", \"a\") as f:\n",
        "            f.write(f\"epoch_num: {args.num_train_epochs}, lr: {args.lr}, batch_size: {args.batch_size}, \" +\n",
        "                   f\"eval_acc: {eval_results['eval_accuracy']:.4f}, test_acc: {test_results['eval_accuracy']:.4f}\\\\n\")\n",
        "        logger.info(f\"Added results to res.txt\")\n",
        "\n",
        "        # Create train loss plot\n",
        "        train_losses = [x[\"loss\"] for x in trainer.state.log_history if \"loss\" in x]\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(train_losses)\n",
        "        plt.title('Training Loss vs Steps')\n",
        "        plt.xlabel('Step')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.grid(True)\n",
        "        plt.savefig('train_loss.png')\n",
        "        logger.info(\"Generated train_loss.png\")\n",
        "\n",
        "    if args.do_predict:\n",
        "        # Get model path\n",
        "        model_path = args.model_path\n",
        "        if model_path is None:\n",
        "            # Try to determine best model from res.txt\n",
        "            try:\n",
        "                best_model = None\n",
        "                best_accuracy = 0.0\n",
        "\n",
        "                with open(\"res.txt\", \"r\") as f:\n",
        "                    for line in f:\n",
        "                        parts = line.strip().split(\", \")\n",
        "                        epoch_num = int(parts[0].split(\": \")[1])\n",
        "                        lr = float(parts[1].split(\": \")[1])\n",
        "                        batch_size = int(parts[2].split(\": \")[1])\n",
        "                        accuracy = float(parts[3].split(\": \")[1])\n",
        "\n",
        "                        if accuracy > best_accuracy:\n",
        "                            best_accuracy = accuracy\n",
        "                            model_path = f\"./modelepoch{epoch_num}lr{lr}_batchsize{batch_size}\"\n",
        "\n",
        "                logger.info(f\"Best model determined from res.txt: {model_path}\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error determining best model: {e}\")\n",
        "                if not args.model_path:\n",
        "                    logger.error(\"No model path specified and couldn't determine best model. Exiting.\")\n",
        "                    return\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            logger.error(f\"Model path {model_path} does not exist\")\n",
        "            return\n",
        "\n",
        "        # Load model for prediction\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "        # Generate predictions\n",
        "        generate_predictions(model, tokenizer, tokenized_datasets[\"test\"], args)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "    # Adjusting line breaks\n",
        "    ex1_code = ex1_code.replace('\\\\n', '\\n')\n",
        "\n",
        "    with open(\"ex1.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(ex1_code)\n",
        "\n",
        "    print(\"ex1.py file created successfully!\")\n",
        "\n",
        "# Time to run!\n",
        "print(\"Starting the process...\")\n",
        "\n",
        "# Setting random seeds\n",
        "set_seed(42)\n",
        "\n",
        "# Creating requirements file\n",
        "create_requirements_file()\n",
        "\n",
        "# Loading the dataset\n",
        "dataset = load_mrpc_dataset(MAX_TRAIN_SAMPLES, MAX_EVAL_SAMPLES, MAX_TEST_SAMPLES)\n",
        "\n",
        "# Loading the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenizing the dataset using the preprocess function\n",
        "tokenized_datasets = dataset.map(\n",
        "    lambda x: preprocess_function(x, tokenizer),\n",
        "    batched=True,\n",
        "    remove_columns=[\"idx\", \"sentence1\", \"sentence2\"]\n",
        ")\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# For storing experiment results\n",
        "all_losses = []\n",
        "all_configs = []\n",
        "\n",
        "# Experiment 1: 1 epoch, learning rate of 0.01, batch size of 16\n",
        "print(\"\\n=== Experiment 1: 1 epoch, learning rate 0.01, batch size 16 ===\\n\")\n",
        "\n",
        "# Initialize wandb for first run\n",
        "run_name = f\"epochs_1_lr_0.01_bs_16\"\n",
        "wandb.login()\n",
        "wandb.init(project='anlp_ex1', name=run_name)\n",
        "\n",
        "# Load model for first experiment\n",
        "model1 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Create training arguments for first experiment\n",
        "training_args1 = TrainingArguments(\n",
        "    output_dir=\"./results_exp1\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=0.01,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    report_to=\"wandb\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer1 = Trainer(\n",
        "    model=model1,\n",
        "    args=training_args1,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer1.train()\n",
        "eval_results1 = trainer1.evaluate()\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results1 = trainer1.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "# Log the results\n",
        "log_results(1, 0.01, 16, eval_results1[\"eval_accuracy\"], test_results1[\"eval_accuracy\"])\n",
        "\n",
        "# Save the model\n",
        "model_path1 = f\"model_ep1_lr001_bs16\"\n",
        "trainer1.save_model(model_path1)\n",
        "\n",
        "# Extract training loss for plotting\n",
        "losses1 = [x[\"loss\"] for x in trainer1.state.log_history if \"loss\" in x]\n",
        "all_losses.append(losses1)\n",
        "all_configs.append({\"num_epochs\": 1, \"lr\": 0.01, \"batch_size\": 16})\n",
        "\n",
        "wandb.finish()\n",
        "\n",
        "# Experiment 2: 3 epochs, learning rate of 4e-5, batch size of 16\n",
        "print(\"\\n=== Experiment 2: 3 epochs, learning rate 4e-5, batch size 16 ===\\n\")\n",
        "\n",
        "# Initialize wandb for second run\n",
        "run_name = f\"epochs_3_lr_4e-5_bs_16\"\n",
        "wandb.init(project='anlp_ex1', name=run_name, reinit=True)\n",
        "\n",
        "# Load model for second experiment\n",
        "model2 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Create training arguments for second experiment\n",
        "training_args2 = TrainingArguments(\n",
        "    output_dir=\"./results_exp2\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=4e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    report_to=\"wandb\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer2 = Trainer(\n",
        "    model=model2,\n",
        "    args=training_args2,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer2.train()\n",
        "eval_results2 = trainer2.evaluate()\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results2 = trainer2.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "# Log the results\n",
        "log_results(3, 4e-5, 16, eval_results2[\"eval_accuracy\"], test_results2[\"eval_accuracy\"])\n",
        "\n",
        "# Save the model\n",
        "model_path2 = f\"model_ep3_lr4e-5_bs16\"\n",
        "trainer2.save_model(model_path2)\n",
        "\n",
        "# Extract training loss for plotting\n",
        "losses2 = [x[\"loss\"] for x in trainer2.state.log_history if \"loss\" in x]\n",
        "all_losses.append(losses2)\n",
        "all_configs.append({\"num_epochs\": 3, \"lr\": 4e-5, \"batch_size\": 16})\n",
        "\n",
        "wandb.finish()\n",
        "\n",
        "# Experiment 3: 5 epochs, learning rate of 5e-5, batch size of 16\n",
        "print(\"\\n=== Experiment 3: 5 epochs, learning rate 5e-5, batch size 16 ===\\n\")\n",
        "\n",
        "# Initialize wandb for new run\n",
        "run_name = f\"epochs_5_lr_5e-5_bs_16\"\n",
        "wandb.init(project='anlp_ex1', name=run_name, reinit=True)\n",
        "\n",
        "# Load a fresh model\n",
        "model3 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Prepare training arguments\n",
        "training_args3 = TrainingArguments(\n",
        "    output_dir=\"./results_exp3\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    report_to=\"wandb\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer3 = Trainer(\n",
        "    model=model3,\n",
        "    args=training_args3,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer3.train()\n",
        "eval_results3 = trainer3.evaluate()\n",
        "\n",
        "# Evaluate on test set\n",
        "test_results3 = trainer3.evaluate(tokenized_datasets[\"test\"])\n",
        "\n",
        "# Log the results\n",
        "log_results(5, 5e-5, 16, eval_results3[\"eval_accuracy\"], test_results3[\"eval_accuracy\"])\n",
        "\n",
        "# Save the model\n",
        "model_path3 = f\"model_ep5_lr00005_bs16\"\n",
        "trainer3.save_model(model_path3)\n",
        "\n",
        "# Extract training loss for plotting\n",
        "losses3 = [x[\"loss\"] for x in trainer3.state.log_history if \"loss\" in x]\n",
        "all_losses.append(losses3)\n",
        "all_configs.append({\"num_epochs\": 5, \"lr\": 5e-5, \"batch_size\": 16})\n",
        "\n",
        "wandb.finish()\n",
        "\n",
        "# Creating combined train_loss.png graph\n",
        "create_loss_plot(all_losses, all_configs)\n",
        "\n",
        "# Finding the best model\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "best_model_path = None\n",
        "\n",
        "for model_info in [\n",
        "    (eval_results1[\"eval_accuracy\"], test_results1[\"eval_accuracy\"], model_path1, model1),\n",
        "    (eval_results2[\"eval_accuracy\"], test_results2[\"eval_accuracy\"], model_path2, model2),\n",
        "    (eval_results3[\"eval_accuracy\"], test_results3[\"eval_accuracy\"], model_path3, model3)\n",
        "]:\n",
        "    val_acc, test_acc, path, model = model_info\n",
        "    if val_acc > best_accuracy:\n",
        "        best_accuracy = val_acc\n",
        "        best_test_accuracy = test_acc\n",
        "        best_model_path = path\n",
        "        best_model = model\n",
        "\n",
        "print(f\"\\nThe best model is: {best_model_path} with validation accuracy of {best_accuracy:.4f} and test accuracy of {best_test_accuracy:.4f}\")\n",
        "\n",
        "# Analyze differences between models\n",
        "print(\"\\n=== Finding examples where models completely disagree (one predicts 0, one predicts 1) ===\\n\")\n",
        "\n",
        "# Identify best and worst models based on validation accuracy\n",
        "worst_accuracy = min(\n",
        "    eval_results1[\"eval_accuracy\"],\n",
        "    eval_results2[\"eval_accuracy\"],\n",
        "    eval_results3[\"eval_accuracy\"]\n",
        ")\n",
        "\n",
        "if worst_accuracy == eval_results1[\"eval_accuracy\"]:\n",
        "    worst_model = model1\n",
        "    worst_model_path = model_path1\n",
        "    print(\"Worst model: 1 epoch, lr=0.01\")\n",
        "elif worst_accuracy == eval_results2[\"eval_accuracy\"]:\n",
        "    worst_model = model2\n",
        "    worst_model_path = model_path2\n",
        "    print(\"Worst model: 3 epochs, lr=4e-5\")\n",
        "else:\n",
        "    worst_model = model3\n",
        "    worst_model_path = model_path3\n",
        "    print(\"Worst model: 5 epochs, lr=5e-5\")\n",
        "\n",
        "# Run analyses on model differences\n",
        "print(f\"Best model: {best_model_path} with accuracy {best_accuracy:.4f}\")\n",
        "print(f\"Worst model: {worst_model_path} with accuracy {worst_accuracy:.4f}\")\n",
        "\n",
        "# Run complete disagreement analysis\n",
        "disagreement_examples = analyze_model_differences_complete_disagreement(\n",
        "    best_model,\n",
        "    worst_model,\n",
        "    tokenizer,\n",
        "    tokenized_datasets[\"validation\"],\n",
        "    dataset[\"validation\"]\n",
        ")\n",
        "\n",
        "print(f\"Analysis complete. Found {len(disagreement_examples)} examples where models completely disagree.\")\n",
        "print(\"Results saved to complete_disagreement_examples.txt\")\n",
        "\n",
        "# Display examples if any were found\n",
        "if len(disagreement_examples) > 0:\n",
        "    print(\"\\nExamples where best model correctly predicted and worst model was wrong:\")\n",
        "    for i, example in enumerate(disagreement_examples[:min(5, len(disagreement_examples))]):\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"Sentence 1: {example['sentence1']}\")\n",
        "        print(f\"Sentence 2: {example['sentence2']}\")\n",
        "        print(f\"True label: {example['true_label']} ({'Paraphrase' if example['true_label'] == 1 else 'Not paraphrase'})\")\n",
        "        print(f\"Best model: Correct ({example['best_pred']}) with confidence {example['best_confidence']:.4f}\")\n",
        "        print(f\"Worst model: Wrong ({example['worst_pred']}) with confidence {example['worst_confidence']:.4f}\")\n",
        "else:\n",
        "    print(\"\\nNo examples found where models completely disagree.\")\n",
        "    print(\"This suggests that the models tend to make similar predictions but differ in confidence level.\")\n",
        "\n",
        "    # If no complete disagreements, look for borderline cases\n",
        "    print(\"\\nInstead, let's find examples where the best model is correct and the worst model is wrong,\")\n",
        "    print(\"even if they predict the same label but with very different confidence levels.\")\n",
        "\n",
        "    # Find edge cases where predictions are similar but confidence levels differ significantly\n",
        "    edge_cases = find_edge_cases(\n",
        "        best_model,\n",
        "        worst_model,\n",
        "        tokenizer,\n",
        "        tokenized_datasets[\"validation\"],\n",
        "        dataset[\"validation\"]\n",
        "    )\n",
        "\n",
        "    print(f\"\\nFound {len(edge_cases)} borderline cases where the worst model almost predicted incorrectly.\")\n",
        "\n",
        "    # Display the edge cases\n",
        "    for i, case in enumerate(edge_cases[:min(5, len(edge_cases))]):\n",
        "        print(f\"\\nBorderline Example {i+1}:\")\n",
        "        print(f\"Sentence 1: {case['sentence1']}\")\n",
        "        print(f\"Sentence 2: {case['sentence2']}\")\n",
        "        print(f\"True label: {case['true_label']} ({'Paraphrase' if case['true_label'] == 1 else 'Not paraphrase'})\")\n",
        "        print(f\"Best model confidence in true label: {case['best_true_conf']:.4f}\")\n",
        "        print(f\"Worst model confidence in true label: {case['worst_true_conf']:.4f}\")\n",
        "        print(f\"Worst model confidence in opposite label: {case['worst_opposite_conf']:.4f}\")\n",
        "\n",
        "# Generate predictions with the best model\n",
        "print(\"\\n=== Generating predictions with the best model ===\\n\")\n",
        "generate_predictions(best_model, tokenizer, tokenized_datasets[\"test\"], dataset[\"test\"])\n",
        "\n",
        "# Create ex1.py file for submission\n",
        "create_ex1_file()\n",
        "\n",
        "print(\"\\nAll required files have been successfully created!\")\n",
        "print(\"- ex1.py: Complete code file with support for all required arguments\")\n",
        "print(\"- res.txt: Results file with validation and test accuracy for all configurations\")\n",
        "print(\"- predictions.txt: Predictions file from the best model on the test set\")\n",
        "print(\"- requirements.txt: File with all required packages\")\n",
        "print(\"- train_loss.png: Training loss graph\")"
      ]
    }
  ]
}